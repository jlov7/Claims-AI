{
    "original_filename": "7762-Article_Text-17157-1-10-20241206.pdf",
    "extraction_timestamp": "2025-05-13T07:34:38.250820",
    "source_file_extension": ".pdf",
    "file_size_bytes": 360441,
    "sha256_hash": "58f8e7239a799aa59dc434a24590533ba9ee3ed8291c1ab28f3821edfcf67d54",
    "content": "International Journal of Communication Networks and Information\nSecurity\n2024, 16(5)\nISSN: 2073-607X,2076-0930\nhttps://ijcnis.org/ Research Article\nBalancing Privacy and Utility in AI Training: Comparative\nAnalysis of Privacy-Preserving Techniques\nArpita Maheriya\nResearch Scholar, Gujarat Technology University, arpita_maheriya@gtu.edu.in\nDr. Shailesh Panchal\nProfessor, Gujarat Technology University-School of Engineering Technological,\nsdpanchal@gtu.edu.in\nARTICLE INFO ABSTRACT\nReceived: 05 Nov 2024 The growing need for data in Artificial Intelligence (AI) training\nAccepted: 06 Dec 2024 and analysis presents a significant challenge on safeguarding\nindividual privacy. Conventional approaches frequently risk\nexposing sensitive information when sharing data. This research\npaper explores privacy-preserving machine learning techniques,\ncomparing k-anonymity, differential privacy, noise addition, data\nsampling, and feature selection. Through sensitivity analysis, it\nwas found that while privacy measures can reduce accuracy,\ncareful parameter adjustments can mitigate these effects.\nConsiderations such as computational overhead, communication\ncosts, scalability, and privacy guarantees are crucial. The study\nemphasizes balancing privacy and model utility and suggests\ndeveloping advanced techniques that minimize information loss\nwithout compromising performance. This work aims to enhance\nprivacy-preserving machine learning by optimizing the balance\nbetween privacy, utility, and scalability.Our hypothesis suggests\nthat our security model minimizes data breach risks and\nunauthorized access, particularly in healthcare, prioritizing\npatient data privacy. This approach aims to advance responsible\nAI development by balancing data analysis with privacy\nprotection.\n1.Introduction\nThe healthcare sector is progressively moving towards digitalization driven by the adoption of\nadvanced technologies and online solutions that enhance user convenience. While these\nadvancements present significant opportunities, they also expose medical organizations to a variety of\nthreats, both digital and nondigital. Such threats have the potential to compromise the security of\nmedical procedures and endanger patient safety [1]. Technical cybersecurity countermeasures now\nsafeguard the confidentiality, integrity, and availability of data and information systems, especially\nwithin the healthcare industry. The sector continues to be besieged by various security threats,\nincluding insider threats, malware, and DDoS attacks [5]. Unlike other industries, healthcare faces\nunique challenges. Protected health information (PHI) is particularly valuable, making it a prime\ntarget for cybercriminals.\nThe evolution of data security concerning medical data in India has been significant. Initially,\npaperbased medical records were common, with security measures relying on physical safeguards like\nlocked cabinets. However, the digitization of healthcare systems in the late 20th century marked a\nmajor shift. The adoption of electronic health records (EHRs) [3] introduced both novel opportunities\nand challenges for data security. While EHRs enhanced efficiency and accessibility, they also\nheightened concerns about the vulnerability of sensitive patient information.\nIndia, similar to many other countries, has encountered numerous challenges related to the\nsecurity of healthcare data over the years. Documented breaches in India’s healthcare sector have\nexposed weaknesses in the systems managing sensitive patient information. These breaches often\nstem from a mix of inadequate cybersecurity measures, outdated technology, and sometimes,\n342 Arpita Maheriya/IJCNIS, 16(5),341-349\nmalicious activities. Such security breaches have led to increased efforts to improve cybersecurity\npractices within the healthcare sector. However, they also highlight the persistent challenges in\nmaintaining the security of medical data. Ensuring the protection of confidential patient data in the\ndigital age requires ongoing and coordinated efforts from healthcare organizations, policymakers, and\ntechnology experts.\n1.1.Cyber Attacks on Healthcare Sector\nCyberattacks on the healthcare sector are an ongoing issue; health data comprise highly detailed\npersonal profiles, rendering them prime targets for fraud, identity theft, and credit card scams.A\ntypical patient's medical record at a healthcare organization includes comprehensive data like the\nindividual's full name, address, date of birth, phone number, email, Social Security (or equivalent)\nnumber, emergency contact details, health insurance information, and occasionally even credit card\nand bank account details. Cybercriminals are indifferent to the size, location, or specific nature of the\nhealthcare provider; their primary objective is to obtain these valuable healthcare records.\nRansomware attacks and data mining efforts have escalated significantly in recent years.\nHospitals are often prone to comply with ransom demands because of the critical need to promptly\nrestore medical systems. The healthcare sector's cybersecurity measures lag behind those of other\nindustries, impeded by legacy systems, insufficient digital literacy among staff, and a lack of\ncomprehensive regulations and enforcement mechanisms [5].\nA major challenge has been the rapid shift to remote healthcare delivery modalities during the\nCOVID19 pandemic [4,14]. Although advanced technology has enabled healthcare professionals to\nmeet increased demand and deliver routine patient care more safely, it has also prompted\norganizations to relax security standards to expand telehealth services. This transition necessitated\nthe rapid deployment of new technological platforms, some of which introduced significant security\nvulnerabilities [10,17].\n1.2.Healthcare Data Sharing\nHealthcare data sharing takes on various forms and purposes. At its core, it involves patients\ndisclosing their health information with healthcare providers for primary use, essential for delivering\nmedical services. Beyond primary use, researchers, innovators, regulators, and public health experts\nmay seek access to this data for secondary purposes. Another perspective on healthcare data sharing\ninvolves distinguishing between individual and aggregate data. Sharing individual data is\ncomparatively straightforward, though challenges such as ensuring access, consent, and\ninteroperability remain significant concerns. In contrast, secondary use often requires aggregating\ndata, which raises critical issues around access and usage, where concerns over data privacy intersect\nwith the requirement for data access and utilization [3].\nDespite the widespread adoption of E-health records, health data remains fragmented and\nisolated, posing significant challenges in accessing data for both primary healthcare needs and\nsecondary uses. Regulatory frameworks have not effectively facilitated data sharing, exacerbating this\nissue [6]. The debate surrounding the balance between using patient data and safeguarding privacy\nrights has gained prominence, particularly following the implementation of the EU General Data\nProtection Regulation (GDPR) [7] in 2018 and the California Consumer Privacy Act (CCPA) in 2020.\nThese regulations have sparked international discussions on the ethical and legal implications of\nsharing large-scale healthcare data. While earlier laws such as the Health Insurance Portability and\nAccountability Act (HIPAA) [8] Privacy Rule in the USA and the Personal Information Protection and\nElectronic Documents Act (PIPEDA) [9] in Canada provided patients with certain data rights, the\nGDPR and CCPA have set new standards by enhancing these protections.\nThe accelerated adoption of telecommuting and telehealth services has amplified concerns\nregarding data security and compliance with regulations such as GDPR and HIPAA. To effectively\ndetect and mitigate potential privacy breaches, healthcare organizations are required to implement\nstrong access control mechanisms, ensure the safe storage and transfer of patient data, and conduct\nregular audits and risk assessments. Additionally, there is a need for continuous monitoring and\nupdating of cybersecurity protocols to address emerging threats and maintain regulatory compliance\n1.3.Privacy policy in India\nIndia commenced its healthcare digitization efforts through the launch of the National Digital\nHealth Mission, now known as Ayushman Bharat Digital Mission (ABDM) [11]. This initiative aims to\nestablish a comprehensive digital infrastructure to support integrated health services nationwide. The\nmission is structured around four core components: the Ayushman Bharat Health Account (ABHA),\nHealthcare Professionals Registry, Health Facility Registry, and Health Information Exchange and\nConsent Manager (HIE-CM). These elements are designed to identify healthcare providers,\n343 Arpita Maheriya/IJCNIS, 16(5),341-349\nprofessionals, and patients, enabling secure exchange of health data with explicit consent from\npatients.\nA significant challenge currently facing this framework is the absence of dedicated data protection\nlegislation. To address this issue, India has proposed the Data Empowerment and Protection\nArchitecture (DEPA) [12] in draft form. DEPA aims to regulate access to health data by public and\nprivate entities through the introduction of 'consent managers'. These managers act as intermediaries\nbetween individuals and datarequesting agencies, facilitating data sharing based on individual consent\nwithout direct access to the data itself. DEPA draws inspiration from the financial sector's practices in\nmanaging data access for rural individuals and small-medium enterprises seeking loans or insurance\nservices. As India advances its E-health agenda, the ABDM strives for an inclusive and consultative\napproach, gathering diverse perspectives to develop a robust strategy for responsible data sharing.\n2.Privacy Preserving Approaches for Healthcare Data Sharing\nThe advancement of information technology has greatly benefited the medical industry through\nthe implementation of health management systems, which have generated substantial volumes of\nhealth big data over time. These health data are exceptionally valuable, as their analysis can uncover\nsignificant opportunities for scientific discoveries, innovations, and ultimately, life-saving\ninterventions [13]. However, sharing health data with organizations and institutions for research and\nanalysis purposes raises privacy concerns patient information. Health data contain sensitive and\npersonal details directly tied to individuals, and unauthorized access or misuse can lead to identity\ntheft, denial of health insurance, and exposure to financial fraud.\nApproach Description Advantages Disadvantages\nAggregation De-identification by All underlying data are Requires understanding\nstoring aggregate deleted except true of initial question in\nanswers and deleting anonymized data. relation to dataset\nunderlying records. answer.\nPrimarily useful for basic\nresearch.\nPseudonymization Replacing identifiable Supports redaction of Artificial identifiers\ninformation with identifying information need review to prevent\npseudonyms (e.g., and linking data across identification.\nreplacing \"Abiodun datasets. Does not\nAdeoye\" with \"efg234\"). anonymize\nsensitive\nattributes.\nRequires careful process\ncontrol to prevent\nreverse engineering.\nSynthetic data Generation of data that No privacy risk as it does Cannot combine\nmimics real data not include real data across\nwithout containing individual data. datasets about the same\nactual individual data. individual.\nData nuances may be\nlost, impacting ML and\nquality improvement\ntasks.\nLimited usefulness for\napplications\nrequiring\ndetailed data\ncharacteristics.\nDifferential privacy Adding random noise to Preserves more Complex computation,\ndata until individual information compared especially for\nidentification becomes to redaction while maintaining utility and\nimpractical. achieving desired privacy level.\nanonymization. Not for\nunstructured\n344 Arpita Maheriya/IJCNIS, 16(5),341-349\ndataset.\nMulti-party computing Collaborative data Allows analysis without Difficult\nanalysis among compromising privacy. algorithm\nmultiple parties without development.\nsharing datasets Slower computation due\ndirectly. to cryptographic\noperations.\nOutput values may still\nreveal identifying\ninformation.\nHomomorphic Performing operations Prevents privacy loss Complex\nencryption on encrypted data during valuable data algorithm\nwithout decrypting it, analysis. development.\npreserving privacy Slow computation due\nduring analysis. to cryptographic\noperations. Output\nvalues may reveal\nidentifying information.\nTabel :1 Privacy Preservation Techniques [15]\nPrivacy-preserving sharing of e-health big data is crucial in the healthcare industry, especially as the\nsharing of data among healthcare providers and organizations grows rapidly [2]. Health data hold\nsignificant value, offering the potential for impactful medical insights and innovations. Conversely,\nthey can additionally be misused for harmful purposes. Ensuring the privacy of patient data is\nparamount, as these records encompass confidential data that can directly identify individuals. Table 1\nprovide information of privacy preserving methods and table 2 show comparative information of\nprivacy preserving tools.\nTool Description Supported Privacy- Key Features Use Cases\nPreserving Models\nARX A comprehensive, open- δ‐Presence, Deletes direct Clinical data sharing\nsource tool for ℓ‐Diversity, identifiers, limits Research projects,\nanonymizing structured k‐Anonymity, t- indirect identifiers Commercial big data\npersonal sensitive data, Closeness, Average Protects sensitive analytics, Biomedical\nwith cross-platform risk, δ‐Disclosure attributes, Handles data analysis,\nfunctionality. privacy, k‐Map, up to 50 attributes Training purposes\nβLikeness, with millions of\nGametheoretic records,\nmodel, Informative GUI\nPopulation for analysis and\nuniqueness, visualization\n(ϵ, δ)\nDifferential privacy.\nAmnesia An anonymization tool k‐Anonymity, km- Provides data European Union's\nwith a user-friendly Anonymity quality “My Health My Data”\ngraphical interface, statistics project\nallowing hierarchy Integrates into\ncreation for tailored projects using ReST\nanonymization. API\nStatistical\nrepresentation of\nreidentified\nprobabilities\n345 Arpita Maheriya/IJCNIS, 16(5),341-349\nOpen- An open-source tool for Differential privacy Facilitates safe data Academic\nDP conducting sharing for institutions\nprivacypreserving scientific research Industries\nanalysis on personal and public interest Government\nsensitive datasets, using exploration agencies conducting\nalgorithms for research and\ndifferentially private exploration\nstatistical releases.\nµ- A tool based on R Randomization, Range of statistical Statistical analysis\nARGUS programming language, Micro-aggregation, anonymization\ndesigned to create Adding noise, Global techniques,\nmicrodata safely, offering recoding, Top and Supports synthetic\nstatistical analysis with bottom coding, data\nvarious anonymization Synthetic data generation\ntechniques. generation\nTabel 2: Privacy Preservation\nTools [15] 3.Aim of the Research\nThe main objective is to investigate and assess different anonymization techniques and algorithms\nto guarantee the privacy and safety of healthcare data, particularly with the rising adoption of\ncentralized and cloud-based servers.\nFigure 1: Aim of the Research\n4.Proposed Methodology\nThe algorithm developed here combines three key concepts in privacy of healthcare data and\nanalysis: k-anonymity, n-gram modelling, and differential privacy. It to assure that the released\ndataset satisfies the k-anonymity criterion, utilizes n-gram modelling for textual analysis, and applies\ndifferential privacy for enhanced data protection. Below, we outline the structured algorithm along\nwith the relevant mathematical formulations.\n• Input: Original dataset D, privacy parameter ϵ for differential privacy, and parameter k for k-\nanonymity.\n• Output: Anonymized and differentially private dataset D′.\n1. Identify quasi-identifiers Q in D that could potentially link data to specific individuals.\n2. For each group, generalize quasi-identifiers to guarantee that records within a group are\nindistinguishable based on Q.\n3. D k−anon =Generalize (D, Q, k)\n4. For each text entry in column C, generate n-grams.\n5. N=n-Gram Frequency (Dk−anon , C, n)\n6. Laplace Mechanism: Noise=Lap (Δ f /ϵ)\n7. D n−gram′=N+ Noise\n8. Replace the original n-gram counts in D k−anon with the noisy counts D’ n−gram.\n9. Release the dataset D′D'D′ which meets the requirements of k-anonymity and differential privacy.\nThis algorithm provides a comprehensive methodology for effectively managing and anonymizing\ntextual data, addressing privacy concerns through a combination of anonymization techniques and\nstatistical noise addition. Each step is designed to protect individuals' privacy represented in the\ndataset while maintaining its usability for analytical purposes.\n346 Arpita Maheriya/IJCNIS, 16(5),341-349\n5.Experiment Result\nIn this experiment Adult Dataset [16] used. On dataset we applied prosed privacy anonymization\ntechniques and other traditional privacy techniques. And after that machine learning, model used for\npredication on anonymized datasets and compared. In Figure 2. Proposed Model excels with the\nhighest accuracy (0.88), precision (0.86), recall (0.89), and F1-score (0.87), suggesting that\nintegrating differential privacy with K-anonymity enhances classification performance. K-anonymity\nfollows with an accuracy of 0.85 and an F1-score of 0.84, showing solid but slightly less balanced\nperformance. Model k-anonymity + AES 256 Bit Encryption, with the lowest accuracy (0.82),\nprecision (0.79), and F1-score (0.82), indicates that AES encryption may introduce noise or data\nutility loss, although it still maintains a competitive recall (0.85). Overall, proposed proves to be the\nmost reliable and balanced among the three.\n0.9\n0.88\n0.86\n0.84 Model A K-anonymity\n0.82 Model B K-anonymity +AES 256\nbit Encryption\n0.8 Model C Proposed\n0.78\n0.76\n0.74\nAccuracy Precision Recall F1-Score\nFigure 2. Comparison with Existing Methods\nFold Accuracy Precision Recall F1-Score\n1 0.85 0.82 0.87 0.84\n2 0.82 0.79 0.85 0.82\n3 0.88 0.86 0.89 0.87\n4 0.84 0.81 0.86 0.83\n5 0.87 0.84 0.88 0.86\nTabel 3: Cross-Validation Matrix Results\nIn Tabel 3. each row represents a fold in the cross-validation process, while each column\ncorresponds to a performance metric (accuracy, precision, recall, F1-score). The values in the table\nreflect the model's performance on each fold, offering insights into its consistency and generalization\nability across various subsets of the data.In Figure 3. Data loss during the anonymization process can\nundermine trust in data protection. If people doubt their data's security, they may be reluctant to\nshare it, hindering research and the implementation of new products and services. The ethical\nimplications of data loss in anonymization are significant, and it's crucial to consider these when\ndeciding how to anonymize data.\n347 Arpita Maheriya/IJCNIS, 16(5),341-349\nM Proposed 23456 7555 Proposed 32.2\nMe\net\nth\nho\nod\nds\nK-anonymity 23456 4582\nK-anonymity 19.53\n0 10000 20000 30000 40000\n0 10 20 30 40\nNumbers of Data\nDataloss Percentage\nOriginal Data Dataloss\nFigure 3. Data loss Comparison after anonymization\nIn Figure 4. For k-anonymity, utility signifies the extent of information loss, reflecting how\nmuch the data has been altered by the anonymization process. For proposed privacy model, utility also\nrepresents information loss or accuracy, but it is measured differently because of the probabilistic\nnature of proposed privacy model, involving the processing of aggregate queries and comparing data\ndistributions before and after applying proposed privacy model. The values highlight the trade-off\nbetween privacy & utility. Typically, as privacy increases (by increasing k for k-anonymity or\ndecreasing epsilon for differential privacy), utility tends to decrease.\n1\n0.8\n0.6\n0.4\n0.2\n0\n2 5 8 10\nk-anonymity differential privacy\nFigure 4. Data utility comparisons (Grey- k-anonymity & Blue-Proposed)\n45\n40\n35\n30\n25\n20\n15\n10\n5\n0\n< 18 >18&&<= 39 >=40&&<=60 >=60&&<=79 >=80\n(Categorical) original dataset (Categorical) anonymized dataset\nFigure 5. Comparison of Categorical Data After Anonymization\n348 Arpita Maheriya/IJCNIS, 16(5),341-349\nIn Figure 5, The anonymization process has preserved the overall distribution patterns of the\noriginal dataset. Minor differences are observed in the frequencies of the 18 to 39 and 40 to 60 age\ngroups, indicating slight changes due to anonymization. Frequencies for the under 18 and 80 and\nabove age groups remain consistently low in both datasets, ensuring rare age groups are similarly\nrepresented post-anonymization. Overall, the chart demonstrates that the anonymization process has\nnot significantly altered the categorical distribution of age groups, maintained the dataset's integrity\nand utility while provided privacy protection. Figure 6 represent comparison in terms of time taken to\nanonymization the data.Figure 7 shows anonymization percentages for different k values (5, 10, and\n20) across various dataset sizes (5k; 10k; and 50k) and Qi values (0.5). The percentages reflect the\nlevel of anonymity achieved, with higher percentages indicating greater anonymization.\nProposed Approach\nK-anonymity + AES256 bit Encryption\nk-anonymity\n0 10 20 30 40 50 60\nDecrypt (ms) CipherText (training(ms)) Encryption (ms)\nFigure 6. Comparison of Anonymization Timings\n100.00 %\n95.00 %\n90.00 %\n85.00 %\n80.00 %\n75.00 %\nK=5 K=10 K =20\nSeries1 Series2 Series3\nFigure 7. Comparison at Different sensitive parameters\n6.Conclusion\nThe anonymization process has effectively preserved the overall distribution patterns of the\noriginal dataset, with only minor variations in the frequencies of certain age groups, thereby\nmaintaining the dataset's integrity and utility while ensuring privacy protection. The utility, reflecting\ninformation loss, varies between k-anonymity and the proposed privacy model because to their\ndistinct approaches. As privacy increases, utility generally decreases. This research demonstrates that\ndata loss during anonymization can undermine trust in data protection, potentially impacting data\nsharing and research. The table of cross-validation results highlights the model's performance\nconsistency and generalization ability. In this paper, with the Adult Dataset, the proposed model,\nwhich integrates differential privacy with k-anonymity, outperformed traditional methods, achieving\n349 Arpita Maheriya/IJCNIS, 16(5),341-349\nthe highest accuracy (0.88), precision (0.86), recall (0.89), and F1-score (0.87). This suggests that the\nintegration enhances classification performance. K-anonymity alone showed solid but slightly less\nbalanced performance, while k-anonymity combined with AES 256-bit encryption had the lowest\nperformance, indicating potential data utility loss due to encryption. Overall, the proposed model\ndemonstrated the highest reliability and balance among the three.\nReferences\n1. Seh, A. H., Zarour, M., Alenezi, M., Sarkar, A. K., Agrawal, A., Kumar, R., & Ahmad Khan, R.\n(2020, May). Healthcare data breaches: insights and implications. In Healthcare (Vol. 8, No.\n2, p. 133). MDPI.\n2. Murdoch, B. (2021). Privacy and artificial intelligence: challenges for protecting health\ninformation in a new era. BMC Medical Ethics, 22, 1-5.\n3. Keshta, I., & Odeh, A. (2021). Security and privacy of electronic health records: Concerns and\nchallenges. Egyptian Informatics Journal, 22(2), 177-183.\n4. Muthuppalaniappan, M., & Stevenson, K. (2021). Healthcare cyber-attacks and the COVID-19\npandemic: an urgent threat to global health. International Journal for Quality in Health\nCare, 33(1), mzaa117.\n5. Bhosale, K. S., Nenova, M., & Iliev, G. (2021, September). A study of cyber attacks: In the\nhealthcare sector. In 2021 Sixth Junior Conference on Lighting (Lighting) (pp. 1-6). IEEE.\n6. Hulsen, T. (2020). Sharing is caring—data sharing initiatives in healthcare. International\njournal of environmental research and public health, 17(9), 3046.\n7. Voigt, P., & Von demBussche, A. (2017). The eu general data protection regulation (gdpr). A\nPractical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676), 10-5555.\n8. Act, A. (1996). Health insurance portability and accountability act of 1996. Public law, 104,\n191.\n9. Act, P. (2000). Personal information protection and electronic documents act. Department of\nJustice, Canada. Full text available at http://laws. justice. gc. ca/en/P-8.6/text. html, 4356-\n4364.\n10. Arpita, M., & Panchal, S. (2022). Smart Health and Cybersecurity in the Era of Artificial\nIntelligence. In Information and Communication Technology for Competitive Strategies\n(ICTCS 2021) Intelligent Strategies for ICT (pp. 41-48). Singapore: Springer Nature\nSingapore.\n11. Sharma, R. S., Rohatgi, A., Jain, S., & Singh, D. (2023). The Ayushman Bharat Digital Mission\n(ABDM): making of India’s digital health story. CSI Transactions on ICT, 11(1), 3-9.\n12. Aayog, N. I. T. I. (2020). Data empowerment and protection architecture. Draft for\nDiscussion, 36-37.\n13. Maheriya, A., & Panchal, S. (2023). A Neoteric Approach to Improvise Privacy Shielding of\nSensitive Healthcare Information & Prediction of Disease. International Journal of\nComputing and Digital Systems, 13(1), 1-12.\n14. Raval, A., & Maheriya, A. (2023). A Survey on Deep Learning Methods for Addressing COVID-\n19 Issues. In Information and Communication Technology for Competitive Strategies\n(ICTCS 2022) Intelligent Strategies for ICT (pp. 61-73). Singapore: Springer Nature\nSingapore.\n15. Privacy-Preserving in E-health Big Data Sharing | by Abiodun I. Adeoye | Medium(last visit:\n12 July 2024)\n16. Adult income dataset (kaggle.com)(last visit: 12 July 2024)\n17. Maheriya, A. A Heuristic Approach to Protect Privacy of Patient’s Sensitive Data with\nPrediction of Disease."
}